{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1483826e",
   "metadata": {},
   "source": [
    "# NLP Pre Training (사전학습)\n",
    "\n",
    "- 대규모의 언어 데이터를 이용하여 미리 만들어진 모델을 이용해, 다른 모델이나 어플리케이션에 적용하는 기법 \n",
    "- 신경망 알고리즘의 전이 학습(Transfer Learning / 특정 대상을 훈련시킨 모델을 다른 대상에도 예측할 수 있도록 바꾸는 머신러닝 기법) 을 활용 \n",
    "- 자연어 처리에서 Pre Training Model \n",
    "    - Pre Training Word Embedding \n",
    "        - 방대한 데이터로 Word2Vec 등과 같은 임베딩 알고리즘으로 사전에 학습된 임베딩 벡터를 가져와 사용하는 방법\n",
    "        - 벡터로만 변환해 처리하기 때문에, 동음이어 구분 불가 \n",
    "        \n",
    "    - Pre Training Language Modeling :\n",
    "        - 모델이 주어진 문장을 바탕으로 다음 단어를 예측해 나가며 학습하는 사전학습 방식\n",
    "        - 문맥을 이해하고 파악하는 방식 / 생성형 모델에 주로 사용 \n",
    "        - GPT (Generative Pre-Trained Transformer)\n",
    "    \n",
    "    - Masked Language Modeling, MLM\n",
    "        - 텍스트에서 무작위로 단어를 가리고(Masking) 모델이 가려진 단어를 채우도록 학습하는 방식 \n",
    "        - 문맥 내 어떤 단어가 자연스럽게 채워지는 지 학습 \n",
    "        - 판별모델에 주로 사용 \n",
    "        - BERT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e252513",
   "metadata": {},
   "source": [
    "# BERT \n",
    "\n",
    "## (Bidirectional Encoder Representation from Transformers)\n",
    "\n",
    "![imge0](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FkZl9A%2Fbtrs5ypcO5M%2Fp49zqNvmpcH4jS4i3TRhn1%2Fimg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6facea",
   "metadata": {},
   "source": [
    "- 위키피디아(25억개 단어)와 BooksCorpus(8억 단어)를 레이블이 없는 텍스트 데이터로 사전 훈련된 언어 모델 \n",
    "- **Fine-Tuning** : 이미 설계된 모델이 다른 작업(다른 데이터)에 대해 파라미터 재 조정하기 위한 추가훈련 과정 \n",
    "- PreTraining 된 BERT 모델을 가져와 챗봇Q&A를 이용하여 Fine-Tuning 실시 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9221f28",
   "metadata": {},
   "source": [
    "- **BERT Model**의 구성\n",
    "    - Word Embedding : BERT는 단어를 Embedding하는 세가지 Embedding 파트가 존재\n",
    "        1. Word Piece Embedding : 단어를 벡터 형태로 변환 Embedding\n",
    "        2. Postition Embedding : 단어의 위치정보를 계산하는 Embedding\n",
    "        3. Segment Embedding : 각 문장을 구분하는 정보를 갖는 Embedding\n",
    "    - 양방향 트랜스포머 구조 (Bidirectional Transformer) :\n",
    "        - BERT는 문장의 앞뒤 문맥을 동시에 고려하여 각 단어의 의미를 이해 \n",
    "        \n",
    "         1. Masked Language Model MLM\n",
    "             - BERT의 핵심 훈련 방식으로, 텍스트에서 무작위로 단어를 가리고 (Masking) 모델이 그 빈자리를 채워 학습 \n",
    "         2. Next Sentence Prediction NSP\n",
    "             - 두 개 문장이 주어졌을 때, 두번째 문장이 첫번째 문장의 논리적인 후속 문장인지를 판별하도록 훈련 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd373c6f",
   "metadata": {},
   "source": [
    "# BERT Embedding \n",
    "\n",
    "- **Word Piece Embedding**\n",
    "    - 입력 Text를 숫자형태의 Vector로 변환 \n",
    "\n",
    "- **Postition Embedding** \n",
    "    - 문맥을 반영한 입베딩(Contextual Embedding)을 사용 \n",
    "    - 단어의 위치정보를 처리하는 Layer를 이용해 학습 \n",
    "    ![imge2](https://wikidocs.net/images/page/115055/%EA%B7%B8%EB%A6%BC5.PNG)\n",
    "\n",
    "- **Segment Embedding**\n",
    "    - 각 문장의 구분을 위한 **Segment Embedding**기법을 사용 \n",
    "    - NSP 다음 문장에 대한 예측을 수행하기 위해 임베딩 \n",
    "    - [CLS] : 문장의 처음을 알리는 토큰 \n",
    "    - [SEP] : 문장과 문장을 구분하는 토큰 \n",
    "        ![imge3](https://wikidocs.net/images/page/115055/%EA%B7%B8%EB%A6%BC7.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e47787",
   "metadata": {},
   "source": [
    "# MLM \n",
    "\n",
    "## (Masked Language Model)\n",
    "\n",
    "- 텍스트에서 임의로 일부 단어를 가리고, 빈칸을 모델이 채우도록 학습 \n",
    "    - 원본 문장 : 나는 고양이와 강아지 중 어떤 걸 키울지 고민이야. \n",
    "    - 마스킹 실시 : 나는 [Mask]와 [Mask] 중 어떤 걸 키울지 고민이야.\n",
    "- BERT는 사전 훈련을 위해서 인공 신경망의 입력으로 들어가는 입력 텍스트의 15%의 단어를 Random으로 Masking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90ab1979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f30873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras 버전이 3이상인 경우 설치 \n",
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4731c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76685d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다 프롬프트 \n",
    "# !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a90d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow를 위한 BERT 모델의 변형 (MLM 수행)\n",
    "from transformers import TFBertForMaskedLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b215b78",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rlack\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForMaskedLM: ['cls.predictions.decoder.bias', 'bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForMaskedLM from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForMaskedLM from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Pre-trainig Model을 호출 \n",
    "# klue (Korean Language Understanding Evaluation) \n",
    "# 한국어 데이터셋을 이용해 사전학습 된 Pre Training Model을 호출 \n",
    "# from_pt=True : 해당 모델을 텐서플로우에서 사용 가능 하도록 옵션 \n",
    "model = TFBertForMaskedLM.from_pretrained('klue/bert-base', from_pt=True)\n",
    "# from_pretrained : 사전 학습 된 모델의 가중치를 로드하여 모델을 초기화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab49926",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7483b26d",
   "metadata": {},
   "source": [
    "- Mask 토큰을 예측 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de9216ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import FillMaskPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf751ac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.10970252752304077,\n",
       "  'token': 8183,\n",
       "  'token_str': '대박',\n",
       "  'sequence': '텔레마케팅 프로젝트는 정말 대박 이다.'},\n",
       " {'score': 0.05240199714899063,\n",
       "  'token': 3841,\n",
       "  'token_str': '최고',\n",
       "  'sequence': '텔레마케팅 프로젝트는 정말 최고 이다.'},\n",
       " {'score': 0.03158402070403099,\n",
       "  'token': 5263,\n",
       "  'token_str': '무료',\n",
       "  'sequence': '텔레마케팅 프로젝트는 정말 무료 이다.'},\n",
       " {'score': 0.028767291456460953,\n",
       "  'token': 3790,\n",
       "  'token_str': '처음',\n",
       "  'sequence': '텔레마케팅 프로젝트는 정말 처음 이다.'},\n",
       " {'score': 0.02510373480618,\n",
       "  'token': 10860,\n",
       "  'token_str': '큰일',\n",
       "  'sequence': '텔레마케팅 프로젝트는 정말 큰일 이다.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = FillMaskPipeline(model=model, tokenizer=tokenizer)\n",
    "pipe(\"텔레마케팅 프로젝트는 정말 [MASK]이다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e128dc4f",
   "metadata": {},
   "source": [
    "# NSP \n",
    "\n",
    "## (Next Sentence Prediction)\n",
    "\n",
    "- 두 개의 문장을 준 뒤, 이 문장이 이어지는 문장인지 아닌지를 판별하는 방식으로 학습 \n",
    "- BERT는 50:50비율로 실제 이어지는 문장과 Random으로 이어붙인 두개의 문장을 주고 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e68eb525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForNextSentencePrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95acd678",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForNextSentencePrediction: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForNextSentencePrediction from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForNextSentencePrediction from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForNextSentencePrediction were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForNextSentencePrediction for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForNextSentencePrediction.from_pretrained('klue/bert-base',\n",
    "                                                   from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7fba0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Softmax\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "610f5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개의 문장이 순차적으로 주어졌을 때, 두 문장이 이어지는 문장인지를 판별 \n",
    "def bert_NSP(first, second):\n",
    "    # 인코딩 \n",
    "    encoding = tokenizer(first, second, return_tensors='tf')\n",
    "    # 모델을 실행 \n",
    "    outputs  = model(encoding['input_ids'], \n",
    "                      token_type_ids=encoding['token_type_ids'])\n",
    "    logits  = outputs.logits\n",
    "    softmax = Softmax()\n",
    "    probs = softmax(logits)\n",
    "    return tf.math.argmax(probs, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a24d6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 문장 입력 \n",
    "first = \"오늘 맛보래 가서 김치찌개 먹었어!!\"\n",
    "second = \"근데 커피를 못마셨네 ㅠㅠ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7215e952",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 : 두 문장이 이어지는 문장 \n",
    "bert_NSP(first, second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0a756b8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = \"오늘 맛보래 가서 김치찌개 먹었어!!\"\n",
    "second = \"난 자연어 처리의 왕이 될꺼야!\"\n",
    "bert_NSP(first, second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe7543",
   "metadata": {},
   "source": [
    "# BERT를 이용한 Chat Bot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70f6523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "384497ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9898ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8d0b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas() # apply 함수를 활용할 때, 진행상황을 Bar 형태로 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "563420d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11823, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Q            A  label\n",
       "0           0        12시 땡!   하루가 또 가네요.      0\n",
       "1           1   1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2           2  3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('39_Data.csv')\n",
    "print(df1.shape)\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d50b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b6d130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c601bd63",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.01795846e-01, -3.44380960e-02,  1.53957236e+00,  1.06975073e-02,\n",
       "        3.79792243e-01,  1.42492890e-01,  1.82864189e-01,  5.58312416e-01,\n",
       "       -3.94889325e-01, -1.17657565e-01, -2.32988864e-01,  3.39581445e-02,\n",
       "       -2.47104242e-01,  3.14535618e-01,  5.60950160e-01, -1.05517283e-01,\n",
       "       -2.92884797e-01, -2.04060242e-01,  3.35199498e-02, -3.21389586e-01,\n",
       "       -1.86384037e-01,  8.55993405e-02,  1.51072219e-01, -3.84577215e-01,\n",
       "       -2.92813510e-01, -4.39995140e-01,  4.83394325e-01, -9.67642903e-01,\n",
       "       -1.51496110e-02,  3.77277075e-03,  2.49316260e-01, -6.04051240e-02,\n",
       "        2.29004756e-01, -2.45080944e-02, -4.22660150e-02, -7.88767487e-02,\n",
       "       -5.18548489e-01, -2.25840006e-02, -1.13830008e-01, -4.75925982e-01,\n",
       "        8.06325793e-01, -3.97932492e-02,  3.83716673e-01,  2.23248690e-01,\n",
       "       -7.62536898e-02, -7.43276477e-02,  3.57227288e-02,  2.59036928e-01,\n",
       "       -3.44938219e-01, -5.93228459e-01, -8.21068406e-01, -4.05041903e-01,\n",
       "        1.16658591e-01,  2.76248455e-01, -2.77389258e-01, -1.15985647e-01,\n",
       "       -1.69148501e-02, -2.52589673e-01,  1.99033484e-01,  6.45438492e-01,\n",
       "        3.94838393e-01, -5.65885544e-01,  3.48211050e-01,  6.53708935e-01,\n",
       "       -1.51743174e-01,  1.77472830e-01,  3.16991597e-01, -3.90328951e-02,\n",
       "       -2.03925744e-01,  4.47613537e-01,  7.11343884e-01,  1.61521643e-01,\n",
       "        1.63215652e-01,  6.00930870e-01, -4.11912173e-01,  6.42713308e-02,\n",
       "        1.76102921e-01,  2.72790641e-01, -1.71842441e-01,  5.50492406e-01,\n",
       "        8.98429602e-02, -7.43766353e-02,  7.03131557e-01,  3.06959242e-01,\n",
       "       -2.12499529e-01,  1.64237618e-01, -2.60773264e-02,  3.11259747e-01,\n",
       "       -1.11680591e+00,  8.49558264e-02, -2.06245705e-01, -1.65326327e-01,\n",
       "        1.49501592e-01, -8.11881348e-02,  3.50532323e-01, -3.27487625e-02,\n",
       "        1.75669089e-01, -3.68082732e-01, -3.00624035e-02, -5.04293323e-01,\n",
       "        1.11778036e-01, -3.23999614e-01,  3.16575736e-01, -2.04705089e-01,\n",
       "        1.89115748e-01,  1.20460935e-01,  2.60310769e-02, -1.99890733e-01,\n",
       "        3.84408921e-01, -4.00854051e-02, -1.18860312e-01,  2.51203448e-01,\n",
       "        5.48249900e-01, -2.80263573e-01, -5.52444682e-02, -3.44351083e-01,\n",
       "       -8.43915939e-01,  9.68619063e-02, -3.57631505e-01,  2.36948237e-01,\n",
       "       -1.40803203e-01,  4.28047627e-01, -3.35394815e-02, -1.45336226e-01,\n",
       "        4.24995422e-01,  6.01650700e-02,  4.91918139e-02, -4.32831854e-01,\n",
       "       -3.50100726e-01,  6.06940798e-02,  3.64145376e-02,  2.19760314e-01,\n",
       "        2.77220160e-01, -1.44413561e-02, -3.52395624e-01, -6.50936291e-02,\n",
       "       -2.00959947e-02, -2.60778248e-01, -2.47231826e-01,  4.89864592e-03,\n",
       "       -6.59800410e-01, -4.18910198e-02, -4.17332262e-01,  4.70647871e-01,\n",
       "        4.09039170e-01, -2.80705988e-01,  1.49572283e-01,  4.83965397e-01,\n",
       "        7.45556131e-02,  2.08360836e-01, -4.58997220e-01,  2.74563640e-01,\n",
       "       -2.17032939e-01, -5.87156713e-01, -4.06832159e-01,  1.44754753e-01,\n",
       "       -1.99766234e-01,  4.79713529e-01,  6.26410618e-02, -8.71979371e-02,\n",
       "        1.96576808e-02,  2.16454536e-01,  2.38484755e-01, -1.90281555e-01,\n",
       "        1.73938558e-01,  1.82548627e-01,  3.07365566e-01,  8.73984277e-01,\n",
       "        2.86491334e-01,  6.01539277e-02,  4.42663640e-01, -8.71541321e-01,\n",
       "       -3.17922205e-01,  2.24062428e-01, -5.71479738e-01,  1.24944009e-01,\n",
       "        4.54143465e-01,  3.55124712e-01,  8.05499494e-01, -6.60692602e-02,\n",
       "        1.92210712e-02,  3.25317159e-02,  8.60579789e-01, -5.56602299e-01,\n",
       "       -1.87823623e-01, -2.26653546e-01, -7.93763027e-02, -3.76430862e-02,\n",
       "        2.43711352e-01,  2.74782747e-01,  4.67746079e-01, -3.68472666e-01,\n",
       "        8.15281272e-02, -6.22514367e-01,  1.44434214e-01,  2.68455893e-01,\n",
       "        1.63412839e-01, -9.28173885e-02,  5.73425815e-02, -1.58299338e-02,\n",
       "        9.91485715e-01, -7.49787837e-02,  2.84643352e-01, -3.07419956e-01,\n",
       "        2.66478270e-01,  7.08610475e-01, -2.23490342e-01,  4.02628571e-01,\n",
       "        2.97814429e-01, -1.58170447e-01, -3.99742067e-01,  1.38767451e-01,\n",
       "        2.20984817e-01,  1.63993463e-01, -1.63063750e-01, -2.46173114e-01,\n",
       "        5.28761387e-01,  1.79198146e-01, -6.08881533e-01, -1.24142691e-01,\n",
       "        1.06608551e-02, -2.35555843e-01,  1.23017766e-01,  1.10557573e-02,\n",
       "       -2.82392025e-01,  3.76598656e-01,  6.73972607e-01, -1.42665043e-01,\n",
       "       -3.48757833e-01, -6.78176224e-01,  3.55276582e-03, -4.57647771e-01,\n",
       "        2.60512710e-01,  3.69137198e-01,  1.16622142e-01,  3.23224783e-01,\n",
       "        1.76298484e-01, -5.12306631e-01, -2.04361543e-01,  2.24245936e-01,\n",
       "        3.92260253e-02,  3.30954731e-01,  1.23414814e-01,  2.17241123e-01,\n",
       "       -6.81395233e-01, -3.34807813e-01,  4.12757248e-01, -1.30156323e-01,\n",
       "       -2.60686334e-02,  4.75108832e-01,  1.68672614e-02, -6.25316501e-01,\n",
       "        3.16544948e-03, -3.47184509e-01, -2.15529546e-01, -3.20267975e-01,\n",
       "       -1.59648255e-01, -1.63771704e-01, -4.20839302e-02, -5.34678936e-01,\n",
       "       -6.20868020e-02, -2.22849980e-01,  1.77798197e-01, -2.24603966e-01,\n",
       "       -2.07822874e-01, -1.71496034e-01, -2.46827260e-01,  7.59336129e-02,\n",
       "        1.23511776e-01, -7.62819275e-02, -1.18948415e-01, -2.35151220e-02,\n",
       "       -2.08623677e-01, -5.02877593e-01,  3.39078397e-01, -4.52606887e-01,\n",
       "        6.02927744e-01, -4.07697000e-02, -5.19592345e-01, -4.42420155e-01,\n",
       "       -1.11626215e-01,  7.33626410e-02, -1.31127059e+00,  5.66786714e-02,\n",
       "        6.91386238e-02, -1.54030293e-01,  4.73951489e-01, -3.03909361e-01,\n",
       "       -3.12107801e-01,  2.12826848e-01, -7.00217366e-01, -5.85060120e-02,\n",
       "       -4.02033925e-02, -8.58194351e-01,  5.23628950e-01, -2.90510595e-01,\n",
       "        1.60149589e-01,  4.57614571e-01, -1.03995109e+00,  4.79551464e-01,\n",
       "       -2.37280980e-01, -1.17141269e-01, -1.37472630e-01,  1.95517346e-01,\n",
       "        9.85762700e-02, -5.02918623e-02, -1.54713899e-01, -1.84979185e-01,\n",
       "       -9.27352235e-02, -2.13718101e-01, -8.15497518e-01, -1.65680334e-01,\n",
       "       -1.51886478e-01, -3.47954556e-02,  7.49207055e-03,  2.68110353e-02,\n",
       "       -4.84740913e-01,  3.44349056e-01,  3.58646438e-02, -6.87108099e-01,\n",
       "        1.60899475e-01,  2.22557038e-01, -9.65479985e-02, -1.20969281e-01,\n",
       "       -2.24649981e-01,  1.15916483e-01, -5.03728867e-01,  4.06520694e-01,\n",
       "        1.19948767e-01, -3.29477608e-01,  1.76169351e-01,  2.56192654e-01,\n",
       "        1.93712249e-01,  1.40511105e-02,  1.17999725e-01,  5.84407330e-01,\n",
       "       -2.36789629e-01, -4.33618009e-01,  3.21099371e-01, -1.21268049e-01,\n",
       "       -1.27479091e-01, -3.86610478e-01, -4.93916035e-01, -2.72125483e-01,\n",
       "        8.05786967e-01, -4.46672380e-01, -3.04576546e-01, -9.34473872e-01,\n",
       "        6.03457093e-01, -4.11168337e-01, -9.35250297e-02,  1.21321142e-01,\n",
       "       -6.62787557e-01,  1.89715773e-01, -6.75872147e-01, -5.18888459e-02,\n",
       "        4.50031847e-01, -2.83228338e-01,  3.29040706e-01,  1.54776052e-01,\n",
       "       -1.49962619e-01, -3.64080578e-01, -3.81194055e-01,  1.82877436e-01,\n",
       "        5.10761142e-02,  9.26495716e-02,  2.99621135e-01, -1.29056945e-01,\n",
       "        9.54631865e-01,  3.97622555e-01,  3.10749233e-01, -3.16856176e-01,\n",
       "        1.40813753e-01, -1.25733286e-01, -3.73099655e-01,  9.81275812e-02,\n",
       "        2.01479986e-01, -5.89842260e-01,  2.55860031e-01,  6.26658648e-02,\n",
       "       -8.34881514e-03, -2.48933092e-01, -1.80402651e-01, -4.08050185e-03,\n",
       "        4.07283396e-01,  1.74254298e-01, -2.58109838e-01, -5.96413910e-01,\n",
       "        7.69235939e-02, -1.77076846e-01,  3.34167898e-01,  2.84491718e-01,\n",
       "        3.01072747e-01,  9.05691385e-02, -9.86365415e-03, -9.76019740e-01,\n",
       "        4.01823580e-01,  1.08954109e-01,  2.40740702e-01,  1.11440904e-01,\n",
       "       -9.14447755e-02,  7.69071519e-01, -2.12062187e-02,  1.91049539e-02,\n",
       "        3.71439941e-02,  3.98361273e-02,  1.40064985e-01, -1.03012882e-01,\n",
       "       -7.11200655e-01, -9.57727805e-02, -1.46295875e-02,  1.09962650e-01,\n",
       "       -5.66301405e-01,  8.76725763e-02, -3.90072912e-01,  3.69467050e-01,\n",
       "       -1.66514128e-01, -5.75613856e-01,  3.27498287e-01,  1.19419329e-01,\n",
       "       -1.93958674e-02, -2.70398438e-01, -4.18122768e-01,  2.92400848e-02,\n",
       "       -9.46791023e-02,  2.46368736e-01,  1.93131536e-01, -6.21826053e-02,\n",
       "       -1.27345026e-01, -7.81165287e-02,  2.00031847e-02,  2.67620772e-01,\n",
       "       -3.44595015e-02,  2.56324816e-03, -1.92946166e-01, -1.04965568e-02,\n",
       "       -3.66205156e-01, -4.65117879e-02,  9.72761288e-02,  9.73975509e-02,\n",
       "        4.86923158e-01,  2.05859929e-01, -5.06206512e-01,  1.87269002e-01,\n",
       "       -2.55500108e-01, -3.93825948e-01, -8.15038197e-03,  1.14037015e-01,\n",
       "       -5.34564145e-02, -9.53997746e-02, -1.50841579e-01,  6.03776336e-01,\n",
       "        1.29424900e-01,  6.05011880e-02,  2.96585232e-01,  1.43204138e-01,\n",
       "       -2.51907557e-01,  1.02480300e-01,  3.70658100e-01, -3.32471162e-01,\n",
       "       -1.47073179e-01, -5.92337191e-01, -2.76258200e-01, -4.80249897e-02,\n",
       "       -2.76806563e-01, -9.81125757e-02, -2.52697498e-01,  3.48157674e-01,\n",
       "       -5.19922189e-02,  2.79675841e-01,  9.41957231e-04,  5.84979868e-03,\n",
       "        1.40537187e-01, -7.78620020e-02,  1.22446418e-02,  8.25204372e-01,\n",
       "       -1.25137508e+00,  2.10088983e-01,  3.99159372e-01, -3.96573022e-02,\n",
       "        2.15700626e-01,  3.46662015e-01, -3.07283431e-01, -1.76794648e-01,\n",
       "       -3.18891287e-01,  2.87184298e-01,  4.02941167e-01, -3.37620378e-02,\n",
       "        4.47072685e-01,  1.41243428e-01, -7.46514142e-01, -5.45688748e-01,\n",
       "       -3.54158074e-01, -2.76190609e-01, -1.96998343e-01,  8.08106542e-01,\n",
       "       -3.56302947e-01, -3.92997675e-02,  1.34840831e-01,  1.50529429e-01,\n",
       "       -3.89244497e-01,  7.22438246e-02, -5.67786157e-01, -4.51273263e-01,\n",
       "        8.94883424e-02,  2.86575884e-01, -5.16263962e-01,  5.65736294e-01,\n",
       "       -2.07359925e-01,  2.29489291e-03, -4.45198476e-01,  6.01469219e-01,\n",
       "       -2.78511614e-01,  8.62424541e-03, -2.08379596e-01, -1.04759507e-01,\n",
       "        6.24432378e-02,  1.89579800e-01,  3.63726556e-01, -8.04549336e-01,\n",
       "        2.91001171e-01,  4.12997119e-02, -1.86892301e-01, -1.10955849e-01,\n",
       "        2.11164221e-01,  1.19908862e-01,  1.17415786e-01, -3.37241560e-01,\n",
       "       -4.42673750e-02, -1.99010000e-01,  5.37535250e-01,  9.90785956e-02,\n",
       "       -1.70595288e-01, -5.57784677e-01,  5.20791054e-01,  4.82368708e-01,\n",
       "       -3.04171145e-01, -2.19484702e-01, -3.50399613e-02,  8.75292867e-02,\n",
       "        1.31928593e-01,  8.75298753e-02,  1.35751888e-02, -2.65768915e-01,\n",
       "       -3.96041065e-01, -4.20371555e-02, -1.26881197e-01,  5.08694863e-03,\n",
       "        2.23855123e-01, -5.69287837e-01, -5.04664302e-01,  1.91901758e-01,\n",
       "       -2.54271179e-01, -5.14789522e-01,  7.08372295e-02, -4.48194653e-01,\n",
       "        3.86592329e-01,  5.76752484e-01,  1.38381869e-01, -4.11393344e-01,\n",
       "        8.21001455e-02, -2.79640526e-01, -2.98675090e-01,  4.57622148e-02,\n",
       "       -3.99850577e-01,  4.61502559e-02,  9.41865370e-02,  3.69002432e-01,\n",
       "        1.91194966e-01,  4.49824380e-03,  2.35153809e-01, -1.67561874e-01,\n",
       "       -1.35037536e-02,  3.35181564e-01, -2.51915753e-01,  1.26504689e-01,\n",
       "        9.18698609e-01,  6.44019246e-02, -9.39804912e-01, -3.39267552e-01,\n",
       "        1.40392646e-01,  4.42800850e-01,  1.15265712e-01, -5.81907213e-01,\n",
       "       -2.58819252e-01, -2.36069098e-01,  3.42406064e-01, -8.32263589e-01,\n",
       "        4.25057143e-01,  6.81658626e-01,  2.48650774e-01, -3.66197318e-01,\n",
       "       -7.40397573e-02, -3.89357626e-01,  3.91254395e-01, -2.89708138e-01,\n",
       "       -1.52726606e-01,  7.58456528e-01, -2.16041788e-01,  6.02031648e-01,\n",
       "       -5.40709555e-01,  1.12735495e-01, -3.38997215e-01,  4.68862265e-01,\n",
       "       -1.28311869e-02,  4.97096516e-02, -2.45472088e-01,  6.37642518e-02,\n",
       "       -1.45828575e-02,  2.16778070e-01,  1.62875980e-01, -2.67206192e-01,\n",
       "       -5.45322418e-01, -1.18970610e-01, -1.27803713e-01, -2.10894197e-01,\n",
       "       -3.33041519e-01,  5.49023688e-01,  6.40497565e-01,  3.65337506e-02,\n",
       "       -9.11252759e-03,  3.63339335e-01, -3.53663951e-01,  1.44043593e-02,\n",
       "       -2.62928247e-01, -1.58498615e-01, -2.87727535e-01, -1.26058990e-02,\n",
       "       -2.96273194e-02, -3.27692702e-02,  2.59475142e-01,  3.71194929e-01,\n",
       "        2.41434112e-01,  2.52480544e-02,  1.11435220e-01,  1.79366350e-01,\n",
       "        2.71439821e-01,  3.72141451e-01,  4.19578582e-01, -2.20182203e-02,\n",
       "       -3.18980627e-02, -5.38097918e-01,  4.28724021e-01, -4.99187499e-01,\n",
       "       -1.22116528e-01, -2.02483267e-01, -4.48814668e-02,  4.92246777e-01,\n",
       "        4.50791091e-01,  5.36573939e-02,  1.17969438e-01, -6.59528375e-01,\n",
       "       -3.81031096e-01,  1.78393170e-01,  1.87153354e-01, -1.83173925e-01,\n",
       "        2.35426813e-01,  4.33732197e-02,  1.34045646e-01, -6.26060128e-01,\n",
       "        3.33491176e-01, -4.88324970e-01,  5.34734763e-02, -1.51319861e-01,\n",
       "       -6.28557354e-02,  1.32774159e-01, -8.75673965e-02, -3.38871717e-01,\n",
       "       -6.43160880e-01, -4.08765554e-01,  3.84317935e-01,  5.24283946e-03,\n",
       "        2.11875588e-01, -7.25906551e-01, -2.49616310e-01, -5.25952950e-02,\n",
       "        5.35762668e-01,  7.06724450e-02,  1.48905441e-01, -2.56414950e-01,\n",
       "        7.17507303e-01,  4.50427949e-01, -9.19040293e-02,  1.72321767e-01,\n",
       "       -3.42429698e-01, -3.68168026e-01,  1.66664198e-01, -2.30315521e-01,\n",
       "       -1.32769585e-01, -2.51554877e-01,  2.77992040e-01,  3.40384901e-01,\n",
       "        5.64982258e-02, -7.66846180e-01,  1.23962045e-01,  3.40730757e-01,\n",
       "        2.26736337e-01, -4.12252456e-01, -1.60144091e-01, -4.17480260e-01,\n",
       "       -2.29608968e-01, -4.06630456e-01, -7.42198765e-01,  1.56839997e-01,\n",
       "       -3.81677896e-01, -5.62519431e-01, -4.86162901e-01,  1.85874835e-01,\n",
       "        1.84700012e-01,  2.25760147e-01,  1.02168210e-01, -1.83373570e-01,\n",
       "       -1.24504857e-01,  5.94500422e-01,  1.87323540e-01,  1.23387361e+00,\n",
       "        1.51119471e-01, -1.42524108e-01,  1.45430773e-01, -2.28005990e-01,\n",
       "       -2.56287724e-01,  3.38832855e-01, -6.03611529e-01,  3.58678959e-02,\n",
       "       -4.59919304e-01,  7.48711675e-02,  1.22307606e-01, -1.94679216e-01,\n",
       "       -7.66730785e-01, -3.14958096e-01, -5.87455392e-01,  3.13935071e-01,\n",
       "       -2.30910286e-01,  4.91282076e-01,  3.40350807e-01,  1.58609394e-02,\n",
       "        2.59203404e-01,  1.46914711e-02,  1.78090841e-01,  4.59876329e-01,\n",
       "       -3.60717118e-01, -5.73601305e-01,  3.41589361e-01, -9.79463235e-02,\n",
       "       -2.20711276e-01, -2.53032893e-01, -6.08240888e-02,  2.02510253e-01,\n",
       "       -2.23969311e-01,  2.30166927e-01, -6.03889562e-02,  1.28891170e-01,\n",
       "       -4.99351114e-01, -7.37029910e-01, -2.39840671e-01,  1.80699788e-02,\n",
       "       -3.26724560e-03,  5.33808134e-02,  1.53538391e-01, -5.38108349e-02,\n",
       "        3.81606907e-01, -1.33928806e-01, -1.89685076e-01, -4.60535347e-01,\n",
       "       -1.08984090e-01,  5.97594045e-02,  1.20592378e-01,  1.19611852e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 인코딩 \n",
    "model.encode(df1['Q'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd5527d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830683fb110d4a58b3a4e7e6d3b90278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1['embedding'] = df1['Q'].progress_apply(lambda x : model.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfe91134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코사인 유사도를 계산하는 함수 \n",
    "def cos_sim(A,B):\n",
    "    return np.dot(A,B) / (np.linalg.norm(A) * np.linalg.norm(B)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "588c384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 질문이 들어왔을 때, 해당 질문에 대한 답변중, 유사도가 가장 높은 \n",
    "# 답변을 출력하는 함수를 구성\n",
    "def return_answer(Q):\n",
    "    embedd = model.encode(Q)\n",
    "    df1['Score'] = df1['embedding'].apply(lambda x : cos_sim(x, embedd))\n",
    "    return df1.loc[df1['Score'].idxmax()]['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76597087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'얼른 맛난 음식 드세요.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "오늘은 맛보래에서 점심을 먹을까? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24b46fbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'먼저 고백해보세요.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_answer('이 과정이 끝나면 그녀에 고백할거야!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c837a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/rlack/OneDrive/BERT_Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3e6aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c514e5ce",
   "metadata": {},
   "source": [
    "# BERT모델 활용 토픽모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bd31bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3b00371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49fc0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29de11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbm_model = KeyBERT(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e08e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"금융 시장은 복잡하고, 그 안에서의 전략과 전술은 수많은 변수에 의해 결정됩니다. 우선, 금융의 세계에서 '전술'이란 단기적 목표를 달성하기 위한 구체적인 행동 방안을 의미합니다. 이는 투자자가 시장의 변동성을 이용하거나, 특정 금융 상품에 집중하는 것과 같은 결정을 포함합니다. \n",
    "전술적 접근은 시장의 단기적 움직임에 초점을 맞추며, 이를 통해 빠른 수익을 창출하려는 목적을 가지고 있습니다. 예를 들어, 경제 지표 발표 전후의 시장 변동성을 이용하여 단기적으로 포지션을 취하는 것이 전술적 투자의 한 예가 될 수 있습니다.\n",
    "반면, 금융 시장에서의 '전략'은 더 장기적인 관점에서 접근합니다. 투자자는 시장의 기본적인 흐름이나, 특정 산업의 장기적 성장 가능성을 분석하여 투자 결정을 내립니다. 이는 주로 광범위한 경제 상황, 산업 동향, 기업의 재무 건전성 등을 기반으로 합니다.\n",
    "금융 시장의 전술과 전략 사이에는 명확한 차이가 존재합니다. 전술은 주로 짧은 시간 내에 수익을 실현하기 위한 목적으로 사용되는 반면, 전략은 장기적인 가치 증대와 안정적인 수익을 목표로 합니다. 이 둘은 상호 보완적이며, 효과적인 포트폴리오 관리를 위해서는 둘 다 중요한 역할을 합니다.\n",
    "경제의 글로벌화가 진행됨에 따라, 금융 전술과 전략의 중요성은 더욱 증가하고 있습니다. 다양한 국가의 금리 정책, 통화 가치 변동, 국제 정치적 사건 등이 글로벌 금융 시장에 직접적인 영향을 미치기 때문입니다. 이러한 환경에서는 유연성과 빠른 대응 능력이 필수적이며, 이를 위해 금융 전문가들은 지속적인 시장 분석과 함께 다양한 전술과 전략을 개발하고 적용하고 있습니다.\n",
    "투자자들은 자신의 투자 목표, 위험 성향, 자본 규모 등을 고려하여 개별적인 전략과 전술을 수립해야 합니다. 이 과정에서 중요한 것은 시장의 변동성과 불확실성에 대비하는 것이며, 이를 통해 장기적으로 안정적인 수익을 창출하는 것입니다.\n",
    "결론적으로, 금융 시장에서 성공적인 투자는 전략과 전술의 적절한 조합을 통해 이루어집니다. 단기적인 시장 변동을 이용하는 전술적 접근과 장기적인 가치 투자 전략이 조화를 이룰 때, 투자자는 불확실한 금융 시장에서도 지속적으로 성장할 수 있는 기반을 마련할 수 있습니다\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817200aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = [x for x in text1.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12e5ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = kbm_model.extract_keywords(sent1, \n",
    "                                      keyphrase_ngram_range=(0,1),\n",
    "                                      top_n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a089744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('금융', 0.466), ('투자자가', 0.3908), ('복잡하고', 0.235), ('변동성을', 0.2181)],\n",
       " [('경제', 0.5164), ('투자의', 0.4115), ('수익을', 0.4031), ('시장', 0.344)],\n",
       " [('투자', 0.5597), ('투자자는', 0.5221), ('금융', 0.5071), ('경제', 0.4902)],\n",
       " [('금융', 0.4032), ('가치', 0.3772), ('수익을', 0.3371), ('전략', 0.2577)],\n",
       " [('글로벌화가', 0.4906), ('금융', 0.3843), ('경제의', 0.3416), ('글로벌', 0.3185)],\n",
       " [('투자자들은', 0.5059), ('투자', 0.4803), ('자본', 0.3595), ('위험', 0.3168)],\n",
       " [('투자는', 0.5074), ('투자', 0.5059), ('투자자는', 0.4727), ('금융', 0.4183)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
